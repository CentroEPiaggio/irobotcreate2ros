{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/fizzer/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/fizzer/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/fizzer/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# from boundbox import BoundBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the robot detects it, it would move towards the arrow, stop, take a picture and determine direction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening Up the Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Annotated Feed', frame)\n",
    "\n",
    "    c = cv2.waitKey(1) # adds delay in feed so we can read \n",
    "    if c == 27: # this is the esc key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting the Outline of the Arrow\n",
    "\n",
    "Displays only the point (all vertical and horizontal lines filtered out). Shows up in red on the final annotated feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code help from https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html \n",
    "# https://stackoverflow.com/questions/19094642/removing-long-horizontal-vertical-lines-from-edge-image-using-opencv\n",
    "# function finds the outline of the arrow and filters out the horizontal and vertical lines so only the pointy part is left\n",
    "\n",
    "def arrow_outline(img):\n",
    "    dst = cv2.Canny(img, 50, 200, None, 3)\n",
    "    \n",
    "    # Copy edges to the images that will display the results in BGR\n",
    "    cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "    cdstP = np.copy(cdst)\n",
    "    \n",
    "    linesP = cv2.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10) #probabilistic line transform\n",
    "    final_pts = []\n",
    "    \n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            \n",
    "            thresh = 30\n",
    "     \n",
    "            if abs(l[1]-l[3]) < thresh: # aka vertical line\n",
    "                pass\n",
    "            elif abs(l[0]-l[2]) < thresh: # aka horizontal line\n",
    "                pass\n",
    "            else:\n",
    "                start_pt = (l[0], l[1])\n",
    "                end_pt = (l[2], l[3])\n",
    "                final_pts.append(start_pt)\n",
    "                final_pts.append(end_pt)\n",
    "                cv2.line(img, start_pt, end_pt, (0,0,255), 3, cv2.LINE_AA)\n",
    "    \n",
    "    return img, final_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data to Determine Arrow Direction\n",
    "\n",
    "Displays text on annotated feed to tell us whether it sees left or right, if at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow_direc(img, arrow_pts):\n",
    "    \n",
    "    if not arrow_pts:\n",
    "        return 'NONE'\n",
    "    \n",
    "    else:\n",
    "        arrow_coords = np.ravel(arrow_pts)\n",
    "        x_list = arrow_coords[::2]\n",
    "        y_list = arrow_coords[1::2]\n",
    "\n",
    "        xmax = np.max(x_list)\n",
    "        xmin = np.min(x_list)\n",
    "        ymax = np.max(y_list)\n",
    "        ymin = np.min(y_list)\n",
    "\n",
    "#         if (xmax, ymax) in arrow_pts:\n",
    "#             return 'LEFT'\n",
    "\n",
    "        if (xmin, ymax) in arrow_pts:\n",
    "            return 'RIGHT'\n",
    "\n",
    "        else:\n",
    "            return 'LEFT'\n",
    "\n",
    "#     arrow_points = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     corners = cv2.goodFeaturesToTrack(gray,4,0.01,10)\n",
    "#     corners = np.int0(corners)\n",
    "\n",
    "#     ct='a'\n",
    "#     for i in corners:\n",
    "#         x,y = i.ravel()\n",
    "# #         print(x,y)\n",
    "#         cv2.circle(img,(x,y),3,(255,255,0),-1)\n",
    "#         cv2.putText(img, ct, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA )\n",
    "#         ct=ct+'a'\n",
    "\n",
    "#     xmax, ymax = (np.max(corners, axis = 0)).ravel()\n",
    "#     xmax_ind, ymax_ind = (np.argmax(corners, axis = 0)).ravel()\n",
    "    \n",
    "#     xmin, ymin = (np.min(corners, axis = 0)).ravel()\n",
    "#     xmin_ind, ymin_ind = (np.argmin(corners, axis = 0)).ravel() \n",
    "    \n",
    "#     if (xmax, ymax) in corners:\n",
    "#         print(\"it's pointing left\")\n",
    "#         return 'LEFT'\n",
    "        \n",
    "#     if (xmin, ymax) in corners:\n",
    "#         print(\"it's pointing right\")\n",
    "#         return 'DOWN'\n",
    "\n",
    "#     else:\n",
    "#         return 'IDK'\n",
    "\n",
    "#     if(np.count_nonzero(corners[:,0,0] == xmax) == 2):\n",
    "#         return'LEFT'\n",
    "#     else:\n",
    "#         return 'RIGHT'\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if( abs(xmax-xmin) > abs(ymax-ymin)):\n",
    "#         if(np.count_nonzero(corners[:,0,0] == xmax) == 2):\n",
    "#             return 'LEFT'\n",
    "#         else:\n",
    "#             return 'RIGHT'\n",
    "#     else:\n",
    "#         if(np.count_nonzero(corners[:,0,1] == ymax) == 2):\n",
    "#             return 'UP'\n",
    "#         else:\n",
    "#             return 'DOWN'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colour Detection - Only for Blue\n",
    "\n",
    "Annotates the feed with a blue bounding box to show where in the feed the colour blue is detected (if at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/multiple-color-detection-in-real-time-using-python-opencv/\n",
    "\n",
    "def blue_detec(imageFrame):\n",
    "        # Convert the imageFrame in \n",
    "    # BGR(RGB color space) to \n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(imageFrame, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "    # Set range for blue color and\n",
    "    # define mask\n",
    "    blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "    blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "      \n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernel = np.ones((5, 5), \"uint8\")\n",
    "      \n",
    "    # For blue color\n",
    "    blue_mask = cv2.dilate(blue_mask, kernel)\n",
    "    res_blue = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "                               mask = blue_mask)\n",
    "\n",
    "  \n",
    "    # Creating contour to track blue color\n",
    "    contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    box_dims = []\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 500):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            imageFrame = cv2.rectangle(imageFrame, (x, y),\n",
    "                                       (x + w, y + h),\n",
    "                                       (255, 0, 0), 2)\n",
    "            box_dims.append((x, y, w, h))\n",
    "\n",
    "    return imageFrame, box_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function - Opens Up Video Feed and Calls Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 1)     # set the frame rate\n",
    "\n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        blue_area, blue_bbox_dims = blue_detec(frame)\n",
    "        \n",
    "        if len(blue_bbox_dims) != 0:\n",
    "            blue = True\n",
    "        else: \n",
    "            blue = False\n",
    "            \n",
    "        arrow_finding, arrow_pts = arrow_outline(frame)\n",
    "        \n",
    "#         direction_finding = arrow_direc(arrow_finding, blue_bbox_dims, arrow_pts)\n",
    "        \n",
    "        direc = arrow_direc(arrow_finding, arrow_pts)\n",
    "        \n",
    "        org = (20, 20)\n",
    "        \n",
    "        if blue is True and direc !='NONE' and direc !='IDK':\n",
    "            cv2.putText(arrow_finding, direc, org, cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1,color = (0, 0, 0), \n",
    "                        thickness = 2 )\n",
    "\n",
    "        cv2.imshow('Annotated Feed', frame)\n",
    "        \n",
    "#         if direction_finding != \"inconclusive\":\n",
    "#             print(\"direction %s\" % direction_finding)\n",
    "\n",
    "        c = cv2.waitKey(1000) # adds delay in feed so we can read \n",
    "        if c == 27: # this is the esc key\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, run this! This calls the main function and starts the magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks whether a point is within a rectangle with given - not used!\n",
    "\n",
    "def solve(bl, tr, p) :\n",
    "    if (p[0] > bl[0] and p[0] < tr[0] and p[1] > bl[1] and p[1] < tr[1]) :\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
